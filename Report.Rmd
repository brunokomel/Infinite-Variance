---
title: "Report"
author: "Derl Clausen, Bruno Komel, Rakeen Tanvir"
date: "5/11/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
<<<<<<< HEAD
#Outline
Exploratory Data Analysis - Center and shape, visualizations, first differences, magnitude, logarithm, 
=======

# Exploratory Data Analysis - Center and shape, visualizations, first differences, magnitude, logarithm, 
##  First differences of Open share price values for DJI data exhibits left skew, large variance, 
>>>>>>> 82efb3591e99a448d0f40ff30b9d062a5509baab
Bootstrapping for empirical cumulative distribution
Bootstrapped sampling distributions and central limit theorem
Partial variance
Pareto analysis
Rare events, linear regression, logistic regression
Hypothesis testing with permutations, contingency tables, and chi-square

Fourier Analysis
Random Walk
Graphical Volatility
Fractal Analysis and Hurst Exponent
Cauchy Distribution
Divergent Integrals
Stable Distribution
Kolmogorov-Smirnov tests
Logarithms, absolute values and varying time horizons

Partial Variance
```{r}
# Partial Variance to test for convergence of variance
N <- length(Open) - 1; 
variances.normal <- variances.cauchy <- variances.Open <- variances.diffs <- numeric(N)
sample.normal <- rnorm(N + 1) ; sample.cauchy <- rcauchy(N + 1)
Open <- DJI$Open ; diffs.Open <- DJI$diffs
index <- 1:N
for (i in 2:(N + 1)) {
  variances.normal[i - 1] <- var(sample.normal[1:i])
  variances.cauchy[i - 1] <- var(sample.cauchy[1:i])
  variances.Open[i - 1] <- var(Open[1:i])
  variances.diffs[i - 1] <- var(diffs.Open[1:i])
}
variances.diffs <- variances.diffs[-1]
par(mfrow = c(2,2)) # create 2x2 plot matrix
plot(index,variances.normal, type = "l", col = "steelblue", log = "x", ylab = "Normal Variance", xlab = "Sample Size") # converges
plot(index,variances.cauchy, type = "l", col = "firebrick", log = "xy",ylab = "Cauchy Variance", xlab = "Sample Size") # diverges jagged
plot(index,variances.Open, type = "l", col = "yellowgreen", log = "xy",ylab = "Open Variance", xlab = "Sample Size") # diverges
plot(head(index,-1),variances.diffs, type = "l", col = "slategray", log = "xy", ylab = "Firs Diff. Variance", xlab = "Sample Size") # diverges
par(mfrow = c(1,1)) # revert to 1x1 plot matrix
summary(variances.normal) # data is centered closely around mean and median
summary(variances.cauchy) # seems to be large spread
summary(variances.Open) # extremely large spread
summary(variances.diffs) # spread is larger than it is for Cauchy but less than Open prices
### Result: As index increases, partial variance converges for normal distribution,
### but it diverges in jagged jumps for Cauchy distribution and
### in smoother curves for both Open values and first differences. 
### This indicates that our data may have undefined or infinite variance. 
```


Divergent Integrals
```{r}
## Divergent Integration For Calculating Variance

#Now let us try to show that, if our data is modeled by a Cauchy distribution with the location and 
#scale parameters above, that it does indeed have infinite variance. 
#To do that, we'll need to define functions that will describe the integrands that will allow us to
#use the tail-integral theorem. First, we'll define the integrand that will give us E(X).
#Since the underlying distribution can be modeled by a Cauchy distribution, we will use 
#dcauchy with the right parameters as our mu_x:
integrand <- function(x) dcauchy(x, location = fit.diffs[1], scale = fit.diffs[2])*x
#and now we have E(X):
exp.x <- integrate(f = integrand, lower = -Inf, upper = Inf)$value; exp.x 

#In the same manner, we can try to calculate E(X^2) so that we can get Var = E(X^2) - E(X)^2
integrand2 <- function(x) dcauchy(x, location = fit.diffs[1], scale = fit.diffs[2])*x^2
#And E(X^2)
exp.x2 <- integrate(f = integrand2, lower = -Inf, upper = Inf)$value; exp.x2 
#And it appears that the integral is divergent! This means that 
#Var = E(X^2) - E(X)^2 also diverges, and thus Var = Inf!
```


#The Impact of Political Regimes - Hypothesis Testing With Permutation Test 
```{r, echo=TRUE}
RepAvg <- sum(DJI$diffs*(DJI$Republican == TRUE))/sum(DJI$Republican == TRUE) ; RepAvg
DemAvg <- sum(DJI$diffs*(DJI$Republican == FALSE))/sum(DJI$Republican == FALSE) ; DemAvg
Obs <-  DemAvg - RepAvg; Obs
#
N <- 10^4 #number of simulations
result.Combined <- numeric(N) #this is the vector that will store our simulated differences
for (i in 1:N) {
  Rep <- sample(DJI$Republican) #This is our permuted party column
  RepMu <- sum(DJI$diffs*(Rep == TRUE))/sum(Rep == TRUE) ; RepMu
  DemMu <- sum(DJI$diffs*(Rep == FALSE))/sum(Rep == FALSE) ; DemMu
  result.Combined[i] <- DemMu - RepMu
  }
mean(result.Combined) #inspecting that these are indeed close to zero
hist(result.Combined, breaks = "FD", probability = TRUE, col = "steelblue")
abline(v = Obs, col = "red")
pvalue <-  (sum(result.Combined >= Obs) + 1)/(N + 1) ; pvalue
```
Giving a p-value of 2.87% chance that this extreme of an observed difference would arise by chance, so it appears that the DJI performed better during democratic regimes, a result that is statistically signifficant.

# Hypothesis Testing: Contingency table with chi-square test for political party and recession. 
```{r,echo=TRUE}
p <- sum(DJI$Recession)/length(DJI$Recession) # 17.67% of observations are in recession years
obs.tbl <- table(DJI$Republican,DJI$Recession)# Republican has more Recession
colnames(obs.tbl) <- c("Expansion", "Recession")
rownames(obs.tbl) <- c("Democrat", "Republican")
exp.tbl <- outer(rowSums(obs.tbl), colSums(obs.tbl))/sum(obs.tbl)
colnames(exp.tbl) <- c("Expansion", "Recession")
rownames(exp.tbl) <- c("Democrat", "Republican")
obs.tbl ; exp.tbl
chisq.test(DJI$Republican,DJI$Recession)
```
As we can see from this contingency table, Republicans had more days in office during recessions, but 
they also had more days in office during expansions.
The result of the chi-square test is a p-value is less than 2.2e-16, far below our .05 threshold, so there would be a verysmall chance that the observed contingency table would arise by chance. Thus, the observations provide sufficient evidence to reject the null hypothesis that Republican and Democratic regimes are equally likely to be associated with recession years from 1985 to early 2020. 

Let us try running this as chi-square test of contingency table including all regimes:
```{r,echo=TRUE}
obs.tbl <- table(DJI$Recession, DJI$Regime); rownames(obs.tbl) <- c("Expansion", "Recession"); obs.tbl #GWB had the most recession days
exp.tbl <- outer(rowSums(obs.tbl), colSums(obs.tbl))/sum(obs.tbl); rownames(exp.tbl) <- c("Expansion", "Recession"); exp.tbl
#This table allows us to see a breakdown of how long each president was in office in terms of recessions and 
#expansions
chisqvalue <- sum((obs.tbl - exp.tbl)^2/exp.tbl)

```
Here we can see that GWB had the most recession days. We can also see how long each president was in office in terms of recessions and how many recession days we would've expected, if they occurred evenly through the years.
```{r,echo=T}
P.Value <- pchisq(chisqvalue, df = (2 - 1) * (6 - 1), lower.tail = FALSE); P.Value
```
And we get a p-value of zero, thus we reject the null hypothesis that recession years are equaly likely to arise across regimes. 

Lastly, we can run this analysis as chi-square test specific to each regime with p the observed probabilty of recession:
```{r, echo=T}
q <- 1 - p; q # 0.8233235 probability of not being in a recession
prob <- (DJI$Recession*p + (!DJI$Recession)*q) / sum(DJI$Recession*p + (!DJI$Recession)*q) 
min(prob) ; max(prob) ; sum(prob) 
for (i in unique(DJI$Regime)) {
  print(chisq.test(DJI$Recession, DJI$Regime == i, p = prob))
}
```
Null hypothesis is that each regime has the observed probability p of recession across regimes. 
Note: There could exist carryover/lingering effects of recession or otherwise from one regime to the next.
Each p-value is less than 2.2e-16, far below the .05 threshold. This indicates that no individual regime is equally likely to be associated with recessions from the years 1985 to early 2020. 


